#aplicando deployment padrão para testar taint e tolerations
kubectl apply -f ./taint_e_tolerations/deployment.yaml

#verificando execução do pod
kubectl get pods -o wide

NAME                               READY   STATUS    RESTARTS   AGE   IP            NODE                                             NOMINATED NODE   READINESS GATES
nginx-deployment-7796b7557-7q855   1/1     Running   0          47s   100.64.2.52   scw-k8s-angry-lovelace-default-104ea93176284d6   <none>           <none>

#verificando nós do clustes
kubectl get nodes

NAME                                             STATUS   ROLES    AGE    VERSION
scw-k8s-angry-lovelace-default-104ea93176284d6   Ready    <none>   156m   v1.22.3
scw-k8s-angry-lovelace-default-4fd0f1d8c47946d   Ready    <none>   156m   v1.22.3
scw-k8s-angry-lovelace-default-fe175434bbd547e   Ready    <none>   156m   v1.22.3

#verificando Taints atribuídos ao nó, deve estar com o valor <none>:
kubectl describe node scw-k8s-angry-lovelace-default-104ea93176284d6

Name:               scw-k8s-angry-lovelace-default-104ea93176284d6
Roles:              <none>
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/instance-type=DEV1-M
                    beta.kubernetes.io/os=linux
                    failure-domain.beta.kubernetes.io/region=fr-par
                    failure-domain.beta.kubernetes.io/zone=fr-par-1
                    k8s.scaleway.com/kapsule=39713063-f994-4dd6-8b91-f0d3fec3607a
                    k8s.scaleway.com/managed=true
                    k8s.scaleway.com/node=104ea931-7628-4d64-b901-85d3c55d499e
                    k8s.scaleway.com/pool=63f48a05-1ab1-49e1-916e-36aab1c39b88
                    k8s.scaleway.com/pool-name=default
                    k8s.scaleway.com/runtime=containerd
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=scw-k8s-angry-lovelace-default-104ea93176284d6
                    kubernetes.io/os=linux
                    node.kubernetes.io/instance-type=DEV1-M
                    topology.csi.scaleway.com/zone=fr-par-1
                    topology.kubernetes.io/region=fr-par
                    topology.kubernetes.io/zone=fr-par-1
Annotations:        csi.volume.kubernetes.io/nodeid: {"csi.scaleway.com":"fr-par-1/8e076646-d3f6-4531-915e-cdfd8b04dd28"}
                    io.cilium.network.ipv4-cilium-host: 100.64.2.130
                    io.cilium.network.ipv4-health-ip: 100.64.2.19
                    io.cilium.network.ipv4-pod-cidr: 100.64.2.0/24
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Tue, 02 Nov 2021 09:34:42 -0300
Taints:             <none>

#aplicando Taints de NoSchedule para que não permita novos agendamento de pods novos no nó scw-k8s-angry-lovelace-default-104ea93176284d6

kubectl taint nodes scw-k8s-angry-lovelace-default-104ea93176284d6 especial=valor1:NoSchedule

#verificando nós do clustes
kubectl describe nodes scw-k8s-angry-lovelace-default-104ea93176284d6

Name:               scw-k8s-angry-lovelace-default-104ea93176284d6
Roles:              <none>
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/instance-type=DEV1-M
                    beta.kubernetes.io/os=linux
                    failure-domain.beta.kubernetes.io/region=fr-par
                    failure-domain.beta.kubernetes.io/zone=fr-par-1
                    k8s.scaleway.com/kapsule=39713063-f994-4dd6-8b91-f0d3fec3607a
                    k8s.scaleway.com/managed=true
                    k8s.scaleway.com/node=104ea931-7628-4d64-b901-85d3c55d499e
                    k8s.scaleway.com/pool=63f48a05-1ab1-49e1-916e-36aab1c39b88
                    k8s.scaleway.com/pool-name=default
                    k8s.scaleway.com/runtime=containerd
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=scw-k8s-angry-lovelace-default-104ea93176284d6
                    kubernetes.io/os=linux
                    node.kubernetes.io/instance-type=DEV1-M
                    topology.csi.scaleway.com/zone=fr-par-1
                    topology.kubernetes.io/region=fr-par
                    topology.kubernetes.io/zone=fr-par-1
Annotations:        csi.volume.kubernetes.io/nodeid: {"csi.scaleway.com":"fr-par-1/8e076646-d3f6-4531-915e-cdfd8b04dd28"}
                    io.cilium.network.ipv4-cilium-host: 100.64.2.130
                    io.cilium.network.ipv4-health-ip: 100.64.2.19
                    io.cilium.network.ipv4-pod-cidr: 100.64.2.0/24
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Tue, 02 Nov 2021 09:34:42 -0300
Taints:             especial=valor1:NoSchedule
Unschedulable:      false


#escalando o deployment para verificar os nós que eles serão feitos deploy
kubectl scale deployment nginx-deployment --replicas=10

#verificando deployment executado
kubectl get pods -o wide

NAME                               READY   STATUS    RESTARTS   AGE   IP             NODE                                             NOMINATED NODE   READINESS GATES
nginx-deployment-7796b7557-589ph   1/1     Running   0          39s   100.64.0.218   scw-k8s-angry-lovelace-default-fe175434bbd547e   <none>           <none>
nginx-deployment-7796b7557-7q855   1/1     Running   0          13m   100.64.2.52    scw-k8s-angry-lovelace-default-104ea93176284d6   <none>           <none>
nginx-deployment-7796b7557-944wt   1/1     Running   0          39s   100.64.1.186   scw-k8s-angry-lovelace-default-4fd0f1d8c47946d   <none>           <none>
nginx-deployment-7796b7557-bkv6r   1/1     Running   0          39s   100.64.0.91    scw-k8s-angry-lovelace-default-fe175434bbd547e   <none>           <none>
nginx-deployment-7796b7557-c6jfp   1/1     Running   0          39s   100.64.0.105   scw-k8s-angry-lovelace-default-fe175434bbd547e   <none>           <none>
nginx-deployment-7796b7557-lm4nf   1/1     Running   0          40s   100.64.0.44    scw-k8s-angry-lovelace-default-fe175434bbd547e   <none>           <none>
nginx-deployment-7796b7557-lv5b7   1/1     Running   0          39s   100.64.1.30    scw-k8s-angry-lovelace-default-4fd0f1d8c47946d   <none>           <none>
nginx-deployment-7796b7557-t7gqg   1/1     Running   0          39s   100.64.1.79    scw-k8s-angry-lovelace-default-4fd0f1d8c47946d   <none>           <none>
nginx-deployment-7796b7557-xbzb7   1/1     Running   0          40s   100.64.1.219   scw-k8s-angry-lovelace-default-4fd0f1d8c47946d   <none>           <none>
nginx-deployment-7796b7557-z6lqx   1/1     Running   0          40s   100.64.1.165   scw-k8s-angry-lovelace-default-4fd0f1d8c47946d   <none>           <none>